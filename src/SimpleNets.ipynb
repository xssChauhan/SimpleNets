{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a Data Loader\n",
    "\n",
    "def load_data(file = \"data/mnist.pkl.gz\"):\n",
    "    f = gzip.open(file,\"rb\")\n",
    "    u = pickle._Unpickler(f)\n",
    "    u.encoding = \"latin1\"\n",
    "    p = u.load()\n",
    "    return p\n",
    "\n",
    "def vectorized_results(j):\n",
    "    e = np.zeros((10,1))\n",
    "    e[j] = 1\n",
    "    return e\n",
    "\n",
    "def load_data_wrapper():\n",
    "    tr_d , va_d , te_d = load_data()\n",
    "    training_inputs = [\n",
    "        np.reshape(x,(784,1)) for x in tr_d[0]\n",
    "    ]\n",
    "    training_results = [\n",
    "        vectorized_results(y) for y in tr_d[1]\n",
    "    ]\n",
    "    training_data = zip(\n",
    "        training_inputs , training_results\n",
    "    )\n",
    "    validation_inputs = [\n",
    "        np.reshape(x,(784,1)) for x in va_d[0]\n",
    "    ]\n",
    "    validation_data = zip(\n",
    "        validation_inputs , va_d[1]\n",
    "    )\n",
    "    test_inputs = [\n",
    "        np.reshape(x , (784,1)) for x in te_d[0]\n",
    "    ]\n",
    "    test_data = zip(test_inputs , te_d[1])\n",
    "    return list(training_data) , list(validation_data) , list(test_data)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BaseNetwork:\n",
    "    \n",
    "    def __init__(self , size , cost = None , batch_size = 1):\n",
    "        self.size = size\n",
    "        self.num_layers = len(size)\n",
    "        self.cost = cost\n",
    "        self.batch_size = batch_size\n",
    "        self.weights = self.initialize_weights()\n",
    "        self.biases = self.initialize_biases()\n",
    "        \n",
    "    def _get_weight_dimensions(self):\n",
    "        '''\n",
    "        Return an iterable with the sizes of weights for each layer\n",
    "        '''\n",
    "        return zip(\n",
    "            self.size[:-1] , self.size[1:]\n",
    "        )\n",
    "    def _get_bias_dimensions(self):\n",
    "        '''\n",
    "        Return an iterable with the sizes of the biases for each layer\n",
    "        '''\n",
    "        return self.size[1:]\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        '''\n",
    "        Initialize the weights using Gaussian distribution with mean 0\n",
    "        and sd 1 over the square root of the number of weights connectin\n",
    "        to the same neuron\n",
    "        '''\n",
    "        sizes = self._get_weight_dimensions()\n",
    "        \n",
    "        return [\n",
    "            np.random.randn(y,x)/np.sqrt(x)\n",
    "            for x,y in sizes\n",
    "        ]\n",
    "    \n",
    "    def initialize_biases(self):\n",
    "        size = self._get_bias_dimensions()\n",
    "        return [\n",
    "            np.random.randn(self.batch_size , y,1) for y in size\n",
    "        ]\n",
    "    \n",
    "    def activation(self , w , b,a):\n",
    "        return sigmoid(\n",
    "            np.matmul(w,a) + b\n",
    "        )\n",
    "        \n",
    "    def inspect(self):\n",
    "        print(\"Weights\")\n",
    "        print([np.shape(e) for e in self.weights ])\n",
    "        print(\"Biases\")\n",
    "        print([np.shape(e) for e in self.biases ])\n",
    "        \n",
    "    def feedforward(self , x):\n",
    "        a = x\n",
    "        for w,b in zip(self.weights , self.biases):\n",
    "            a = self.activation(w,b,a)\n",
    "        return a\n",
    "    \n",
    "    def backprop(self , x , y):\n",
    "        '''\n",
    "        Implement the backprop Pipeline\n",
    "        '''\n",
    "        return\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights\n",
      "[(30, 784), (10, 30)]\n",
      "Biases\n",
      "[(10, 30, 1), (10, 10, 1)]\n"
     ]
    }
   ],
   "source": [
    "tr_d , va_d , te_d = load_data_wrapper()\n",
    "net = BaseNetwork([784 , 30 , 10] , batch_size = 10)\n",
    "net.inspect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
